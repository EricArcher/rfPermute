---
title: "rfPermute: Estimation of predictor importance significance in Random Forest models"
author: "Frederick I. Archer"
output: 
  pdf_document:
    fig_caption: yes
    keep_tex: yes
bibliography: archer.bib
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy = TRUE, cache = TRUE, comment = "")
```

## Abstract

One of the strengths of the ensemble machine learning algorithm, Random Forest, is its ability to estimate the relative importance of predictors within classification and regression models. However, there is no method for identifying which predictors are significantly more important than what would be expected by random chance. I present the *rfPermute* package which is a wrapper for the commonly used *randomForest* package that produces permutation-based estimates of predictor importance significance. The package also includes utility functions for summarizing and visualizing Random Forest model results.

## Introduction

Since its inception, the ensemble machine learning algorithm, Random Forest [@RN266], has been rapidly gaining popularity as a powerful tool for classification and uncovering patterns in complex data sets. Because it is non-parametric and produces internally-validated classification models, it has been used in a wide variety of fields [@RN126; @RN128; @RN268], and has proven to be robust in performance tests against other commonly used modelling algorithms [@RN125].  

The most common implementation of Random Forest is the *randomForest* package [@RN127]. This package allows easy specification of both classification and regression models and provides several useful functions for summarizing their results. One of the metrics that many users of Random Forest are interested in examining are the measures of variable or predictor importance. The importance of a predictor is estimated by measuring the decrease in prediction accuracy when that predictor is permuted in each tree in the forest. These values are often used to identify and rank those predictors that are most related to the response and critical for classification. More detail about how the various importance metrics are computed can be found in @RN403, @RN127, as well as the help file for the `importance` function in *randomForest*.  
However, *randomForest* only produces raw measures of predictor importance and it is up to the user to identify cutoff values above which predictors would be considered to have a significant impact on model predictions. In order to address this, I have implemented a permutation test called *rfPermute* which generates a null distribution of importance scores for each predictor against which the observed importance scores are compared. This null distribution is created by randomly permuting the response variable (class assignments in a classification model, or independent continuous response in a regression model) among cases, running the same Random Forest model on the permuted data, and storing the resulting importance scores. 

Under this procedure, a predictor that is not adding any significant information to the model will have an observed importance score that is similar to those generated by a random shuffling of the response, while a significant predictor will have an importance score much larger than the null. Significance p-values are then calculated as the fraction of replicates in the null distribution that are greater than or equal to the observed value. *rfPermute* provides both the p-values and the null distribution which the user can use for variable selection and further exploration.

## Execution

The function, `rfPermute`, provides a wrapper for the `randomForest` function that accepts all of its arguments, plus two additional ones: `nrep`, which is an integer specifying the number of permutation replicates to run, and `num.cores`, which is an integer specifying the number of CPU cores to distribute the permutations over on a multi-core system. If `nrep` is set to 0, then the return value is a list with the same elements as the equivalent call to `randomForest`. With one or more permutation replicates specified, the returned list contains two elements: `null.dist`, which is a list containing arrays of the null distributions for unscaled and scaled importance measures, and `pval`, which is an array containing the permutation p-values for unscaled and scaled importance measures.  

As an example, we use `rfPermute` to create a classifier of four clades of the endosymbiont dinoflagellate *Symbiodinium* from a data set of metabolite profiles as published in Klueter et al (2015). Significance is measured with 1000 permutations. Because each *Symbiodinium* type is represented by 16 cases in this data set, we create a model where 8 cases from each type are used in each tree, and sampling is done without replacement. This scheme ensures that in each tree, half of the samples from each class are used for trainng, while the other half are retained as out-of-bag (OOB) for testing. `rfPermute` automatically sets `importance = TRUE` to force `randomForest` to calculate and return the matrix of importance scores, so we don't need to set that. However, we will be using the proximity matrix later, so we must specify `proximity = TRUE`.

```{r load_pkg, include = FALSE}
library(rfPermute)
```
```{r load_pkg2, eval = FALSE}
# Load the package
library(rfPermute)
```
```{r run_model}
# Load the metabolomics data set
data(symb.metab)

# Create the randomForest model with 1000 permutations. 
metab.rf <- rfPermute(type ~ ., data = symb.metab, sampsize = rep(8, 4), replace = FALSE, proximity = TRUE, nrep = 1000)
metab.rf
```

The result is a `rfPermute` object that inherits from and has the same components as a `randomForest` object, plus `null.dist` and `pval`, as seen below.

```{r view_model}
class(metab.rf)
names(metab.rf)
str(metab.rf$null.dist)
str(metab.rf$pval)
```

## Predictor significance

The permutation p-values for predictors in the `rfPermute` object can be accessed using the `rp.importance` function, which behaves in the same manner as `randomForest::importance`, returning a matrix of the scaled or unscaled importance scores along with their respective p-values.

```{r importance}
imp <- rp.importance(metab.rf)
head(imp)
```

A density plot of the null distribution of predictor importances along with the observed importance value can be visulized with the `plotNull` function (Fig. 1). 

```{r plotNull, fig.cap = "Null distribution of mean decrease in accuracy for the predictor metabolite, 'Disaccharide.8'."}
plotNull(metab.rf, preds = "Disaccharide.8", imp.type = "MeanDecreaseAccuracy")
```

An ordered bar chart of all predictor importances with designations of their significance at a specified critical \(\alpha\) (traditionally 0.05), can be visualized with the `plot` function applied to the result of `rp.importance`. Figure 2 shows that approximately the top third of the predictor metabolites are deemed significant at p <= 0.05, even though the distributon of importance scores shows a steady decline with no obvious break in this region.

```{r plot_imp1, fig.cap = "Bar chart of mean decrease in accuracy. Bars colored in red have p-values <= 0.05."}
plot(imp, type = "MeanDecreaseAccuracy")
```

Given that we can't see much detail about specific predictor metabolites, we can also show just the top 10 most important predictors, but this time for all importance types (Fig. 3). The figure can also be restricted to show only significant predictors by specifying `sig.only = TRUE` to the `plot` function.

```{r plot_imp2, fig.cap = "Bar chart of top ten most important predictors."}
plot(imp, n = 10)
```

Figure 3 shows that many of the same metabolites are significantly important for all classes. To better visualize the relative distribution of predictor importance across classes we can also produce a heatmap (Fig. 4). Although many of the same metabolites rank high for all classes, there are several lower down in the list that are significant in some classes, but not in others, suggesting that they have strong diagnostic properties for those subsets of classes.

```{r impHeatmap, fig.cap = "Heatmap of top 30 most important predictor metabolites, color coded by rank order. Cells encircled by black have p-values <= 0.05."}
impHeatmap(metab.rf, n = 30)
```

## Model summary functions

`rfPermute` also provides a set of convenient summary functions for *randomForest* models, regardless of if the model was run in *randomForest* or *rfPermute*. In order to evaluate how well a classification model is performing, one should compare the observed OOB error rates to what would be expected if samples were just randomly allocated to bins in the absence of information from predictor variables. This rate turns out to simply be the fraction of the total sample size represented by each class. In a simple two-class model, with equal sample sizes in each class, this is then 50% for both classes. However, if the sample sizes are skewed, say 80 in class A, and 10 in class B, then one would expect on average to correctly classify 80 / 90 of the class A samples and 10 / 90 of the class B samples. Thus the expected error rates would be 0.11 for class A and 0.89 for class B. These values, referred to as "priors" are calculated by the `exptdErrRate` function. Since this data set has equal sample sizes, all priors are the same: 

```{r exptdErrRate}
exptdErrRate(metab.rf)
```

The `classConfInt` function provides confidence intervals for the class-specific and overall model classification scores based on a binomial distribution. This helps provide a measure of uncertainty of the true classification rate given the observed sample sizes.

```{r classConfInt}
classConfInt(metab.rf)
```

The first column in the output is the oberved percent correct (1 - OOB error rate). The next two columns are the bounds of the central 95-percentile of the classification score given the observed sample sizes. The final column provides the fraction of the binomial distribution that is greater than a given threshold. The default is 0.8, but it can be specified using the `threshold` argument.

A complete summary of the *randomForest* classification model can be produced by combining the results of `classConfInt` and `exptdErrRate` along with the full confusion matrix as in the function, `confusionMatrix`.

```{r confusionMatrix}
confusionMatrix(metab.rf)
```

Note that in this matrix, the columns deriving from the `classConfInt` function are multiplied by 100, and `Prior` is 100 * (1 - expected error rate), as I have found that this scale to be more easily communicated in publications.

## Vote distributions

When evaluating a Random Forest model, it can be useful to visualize the distribution of votes for classes within the forest. From these distributions, we can tell if individual cases are tending to be correctly classified with large probabilities (have a high fraction of trees voting for the correct class), or have equivocal assignments (vote probabilities are roughly equal). We can also see if misclassified samples were strongly or weakly misclassified. The `plotVotes` function will produce such a distribution, either as a bar chart, which is useful when few samples are present, or as an area chart, which is more readable with many samples.

```{r plotVotes, fig.cap = "Distribution of votes in the Random Forest for samples of each of the four *Symbiodinium* types."}
plotVotes(metab.rf)
```

Figure 5 shows that *Symbiodinium* types A194 and D206 have many of their members classified with a relatively large fraction of votes. We also see that the two B224 samples that were misclassified to D206 only had about 30% of the votes to D206, which is not a strong misclassification. 

## Proximity plots

For visualizing the relative distribution of samples in the Random Forest, multi-dimensional scaling (MDS) is applied to the proxmity matrix computed by `randomForest`. The *randomForest* package provides the `MDSplot` function which uses *base* graphics to visualize these points. In *rfPermute* there is the `proximityPlot` function which uses *ggplot2* graphics [@Wickham2009] and provides a few additional useful features. The result of `proximityPlot` depicts the MDS projection of cases, with classes encircled by a shaded convex hull. Additionally, each case is represented by a color-coded dot and circle. The color of the interior dot corresponds to the original case, while the color of the exterior circle corresponds to the predicted case. Thus, correctly classified cases will have the same color, while misclassified cases will have different colors.

```{r proximityPlot, fig.cap = "Proximity plot of *Symbiodinium* samples."}
proximityPlot(metab.rf)
```

In Figure 6, the two misclassified B224 samples are near the periphery of the D206 convex hull, some distance away from the majority of the other B224 samples, but also separated from the majority of the D206 samples. Given the variability in B224, we might then view these as aberrant B224 samples rather than mislabelled D206 samples.

All graphical output in *rfPermute* is produced using the *ggplot* package. Functions that produce figures will also invisibly return the *ggplot2* object generated so that they can be further modified if desired. The `proximityPlot` function also returns the MDS matrix resulting from a call to `cmdscale`. 

## Performance

Because the primary function, `rfPermute`, is a wrapper that calls `randomForest` multiple times, execution time can be lengthy for large data sets and will scale relatively linearly with the number of permutations. However, execution time can be reduced if a multi-core machine is used and the `num.cores` argument set appropriately. For example, on a MacBook Pro with a 2.8GHz Intel Core i7 chip and 16GB of 1600 MHz DDR3 RAM, one `randomForest` run of the *Symbiodinium* data set took approximately 0.1 seconds. The same `rfPermute` model with 100 replicates took 14.4 seconds, and 1000 replicates took 142.3 seconds. When the number of cores used was increased from one to three, the 1000 replicate model took 46 seconds.

Efficiency can also be enhanced by running the same *rfPermute* model can on multiple systems and combining the results later using the `rp.combine` function. This function is the equivalent of `randomForest::combine` and takes a set of the same `rfPermute` models as its arguments.

## Installation

The stable version of *rfPermute* can be installed from CRAN via:
```{r eval = FALSE}
install.packages('rfPermute')
```
To install the latest development version from GitHub, use:
```{r eval = FALSE}
# make sure you have Rtools installed
if (!require('devtools')) install.packages('devtools')

# install from GitHub
devtools::install_github('EricArcher/rfPermute')
```

## References
